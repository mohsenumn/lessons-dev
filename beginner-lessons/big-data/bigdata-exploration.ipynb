{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c722dc46",
   "metadata": {},
   "source": [
    "## Big Data\n",
    "\n",
    "### Segment 3 of 3\n",
    "# Exploration\n",
    "\n",
    "<i>Lesson Developers: </i>\n",
    "<ul>\n",
    "    <li>\n",
    "    <i>Edwin Chow, chow@txstate.edu</i>\n",
    "    </li>\n",
    "    <li>\n",
    "    <i>Jayakrishnan Ajayakumar, jxa421@case.edu</i>\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ca836",
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "Hide"
    ]
   },
   "outputs": [],
   "source": [
    "# This code cell starts the necessary setup for Hour of CI lesson notebooks.\n",
    "# First, it enables users to hide and unhide code by producing a 'Toggle raw code' button below.\n",
    "# Second, it imports the hourofci package, which is necessary for lessons and interactive Jupyter Widgets.\n",
    "# Third, it helps hide/control other aspects of Jupyter Notebooks to improve the user experience\n",
    "# This is an initialization cell\n",
    "# It is not displayed because the Slide Type is 'Skip'\n",
    "\n",
    "from IPython.display import HTML, IFrame, Javascript, display\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "import pandas as pd\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import getpass # This library allows us to get the username (User agent string)\n",
    "\n",
    "# import package for hourofci project\n",
    "import sys\n",
    "sys.path.append('../../supplementary') # relative path (may change depending on the location of the lesson notebook)\n",
    "import hourofci\n",
    "\n",
    "\n",
    "# load javascript to initialize/hide cells, get user agent string, and hide output indicator\n",
    "# hide code by introducing a toggle button \"Toggle raw code\"\n",
    "HTML(''' \n",
    "    <script type=\"text/javascript\" src=\\\"../../supplementary/js/custom.js\\\"></script>\n",
    "    \n",
    "    <style>\n",
    "        .output_prompt{opacity:0;}\n",
    "    </style>\n",
    "    \n",
    "    <input id=\"toggle_code\" type=\"button\" value=\"Toggle raw code\">\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4c795",
   "metadata": {},
   "source": [
    "## Reminder\n",
    "<a href=\"#/slide-2-0\" class=\"navigate-right\" style=\"background-color:blue;color:white;padding:8px;margin:2px;font-weight:bold;\">Continue with the lesson</a>\n",
    "\n",
    "<br>\n",
    "</br>\n",
    "<font size=\"+1\">\n",
    "\n",
    "By continuing with this lesson you are granting your permission to take part in this research study for the Hour of Cyberinfrastructure: Developing Cyber Literacy for GIScience project. In this study, you will be learning about cyberinfrastructure and related concepts using a web-based platform that will take approximately one hour per lesson. Participation in this study is voluntary.\n",
    "\n",
    "Participants in this research must be 18 years or older. If you are under the age of 18 then please exit this webpage or navigate to another website such as the Hour of Code at https://hourofcode.com, which is designed for K-12 students.\n",
    "\n",
    "If you are not interested in participating please exit the browser or navigate to this website: http://www.umn.edu. Your participation is voluntary and you are free to stop the lesson at any time.\n",
    "\n",
    "For the full description please navigate to this website: <a href=\"../../gateway-lesson/gateway/gateway-1.ipynb\">Gateway Lesson Research Study Permission</a>.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626db606",
   "metadata": {},
   "source": [
    "If you have large volume of Spatial Big Data that is essentially static or is updated only once in a few days or months or years, then we can easily solve those challenges with adequate computational resources. For example the crime data from the City of Chicago has more than 7 million records, but it is not updated in real-time (in fact it is updated weekly). So we do have a buffer of 7 days to process the incoming data and make sense of it. \n",
    "\n",
    "But the real computational challenge associated with Spatial Big Data is when the data gets updated in real-time (milliseconds, seconds, minutes). Now we have to process large volume of data in real-time. We have already seen some examples in the Introduction session. \n",
    "\n",
    "One of the biggest challenges of handling SBD or even BD with high velocity is that the processing has to keep abreast with the enormous data that is getting generated in real-time. If data processing cannot keep up with data ingestion then the end result is <span STYLE=\"font-size:18.0pt;color:black\">Data Loss</span>.\n",
    "\n",
    "<img src = \"supplementary/firehose.jpg\" width = 50%>\n",
    "\n",
    "Let's check out the Velocity aspect of SBD through some real world examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c085d9",
   "metadata": {},
   "source": [
    "## An hour in NYC (From a Yellow Cab Perspective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e355a87",
   "metadata": {},
   "source": [
    "![yellow_taxi](supplementary/yellow_taxi.jpg)\n",
    "Yellow taxicabs are widely recognized as a symbol for NYC. There are almost 13,587 yellow cabs in NYC. NYC Taxi and Limousine Commission TLC releases Trip Record Data (https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The Trip record data includes pick-up and drop-off dates/times, pick-up and drop-off locations (the spatial component), trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts.\n",
    "\n",
    "The taxi dataset you are going to use for this lesson is an extract from the entire dataset. It contains the trip record for 1 hour. While the taxi records only contain the pick-up and drop-off locations, we have generated a GPS trajectory dataset for each taxi based on its pick-up and drop-off location. \n",
    "\n",
    "Let's get into action with our first experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237c1d0",
   "metadata": {},
   "source": [
    "### Experiment I (Taxis Taxis Everywhere!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa133e68",
   "metadata": {},
   "source": [
    "Let's explore the dataset first\n",
    "\n",
    "Our data is in parquet format which is particularly designed for columnar storage and is highly optimized for storing large amount of data. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "data = pd.read_parquet(r'supplementary/taxi1hr_gps.parquet')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d1688c",
   "metadata": {},
   "source": [
    "There are 10,891,783 coordinates even for 1 hour taxi trajectory data. The id is unique for each taxi and sec indicates the current sec from the start of the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c094952",
   "metadata": {},
   "source": [
    "You can click on the Start Simulation Button to see the taxis in action!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac31f73",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [],
   "source": [
    "class GPSThread(threading.Thread):\n",
    "    # we will use two queues, one for pushing the GPS data and other to recieve any message from main thread\n",
    "    def __init__(self, dataDict,status):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.dataDict = dataDict\n",
    "        self.status = status\n",
    "    def run(self):\n",
    "        #load the data file\n",
    "        data = pd.read_parquet(r'supplementary/taxi1hr_gps.parquet')\n",
    "        #create an index based on seconds \n",
    "        data.set_index('sec',inplace=True)\n",
    "        #now we need to loop through the dataset\n",
    "        for sec in range(data.index.min(),data.index.max()):\n",
    "            #kill switch is a message in the message queue\n",
    "            if self.status[0]==0:\n",
    "                break\n",
    "            dat = data.loc[sec]\n",
    "            self.dataDict[sec] = dat[['id','lng','lat']]\n",
    "            #after one iteration sleep for a second......\n",
    "            time.sleep(1)\n",
    "        #if simulation is over put a pill in the outQueue\n",
    "        self.status[0] = 2\n",
    "atDict = {}\n",
    "status = [-1]\n",
    "def start():\n",
    "    global datDict\n",
    "    global status\n",
    "    datDict = {}\n",
    "    status[0] = 1\n",
    "    gpsThread = GPSThread(datDict,status)\n",
    "    gpsThread.start()\n",
    "    #small delay for the thread to startup\n",
    "    time.sleep(.5)\n",
    "    return \"started\"\n",
    "def getData(sec):\n",
    "    if status[0] == 2 or status[0] == 0:\n",
    "        return \"sim over\"\n",
    "    if sec in datDict:\n",
    "        return datDict.pop(sec).to_json(orient=\"records\")\n",
    "    return \"No Data\"   \n",
    "def stop():\n",
    "    global status\n",
    "    status[0] = 0\n",
    "    return \"stopping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914372b",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.8.0/dist/leaflet.css\"/>\n",
    "<div id=\"main\">\n",
    "    <div id=\"map\"></div>\n",
    "    <div id=\"controls\">\n",
    "        <button id=\"start_button\" class =\"controlbuttons\" onclick = \"run()\">Start Simulation</button>\n",
    "        <button id=\"stop_button\" class =\"controlbuttons\" onclick = \"stop()\" disabled>Stop Simulation</button>\n",
    "        <span id=\"active_cars\" class =\"controlbuttons\">Active Cars:0</span>\n",
    "    </div>\n",
    "</div>\n",
    "<style>\n",
    "#main { height: 500px;width:800px; }\n",
    "#map { height: 75%;width:100%; }\n",
    "#controls { height: 20%;margin-top:4%; }\n",
    ".controlbuttons{float:left;margin:1%;}\n",
    "</style>\n",
    "<script>\n",
    "    var map,datInterval,current;\n",
    "    require.config({ \n",
    "        paths: { \n",
    "             d3: 'https://d3js.org/d3.v7.min',\n",
    "             L: 'https://unpkg.com/leaflet@1.8.0/dist/leaflet'\n",
    "        }});\n",
    "    \n",
    "    function fetch(){\n",
    "        IPython.notebook.kernel.execute(\n",
    "            \"getData(\"+current+\")\", \n",
    "            {\n",
    "                iopub: {\n",
    "                    output: function(response) {\n",
    "                        // Print the return value of the Python code to the console\n",
    "                        var dataString = response.content.data['text/plain'];\n",
    "                        if (dataString.includes(\"sim over\")){\n",
    "                            console.log('Time to clean up');\n",
    "                            require(['d3'], function(d3) { \n",
    "                                d3.select(\"#map\")\n",
    "                                        .select(\"svg\")\n",
    "                                        .selectAll(\"circle\").remove();\n",
    "                            });\n",
    "                            clearInterval(datInterval)\n",
    "                            current=0;\n",
    "                            //enable the start button\n",
    "                            document.getElementById(\"start_button\").disabled = false;\n",
    "                            document.getElementById(\"stop_button\").disabled = true;\n",
    "                            document.getElementById(\"active_cars\").innerText = \"Active Cars:0\";\n",
    "                        }\n",
    "                        else if (dataString.includes(\"No Data\")){\n",
    "                            console.log('No data for '+current)\n",
    "                        }\n",
    "                        else{\n",
    "                            require(['d3'], function(d3) { \n",
    "                                var data = JSON.parse(dataString.slice(1,dataString.length-1));\n",
    "                                document.getElementById(\"active_cars\").innerText = \"Active Cars: \"+data.length;\n",
    "                                d3.select(\"#map\")\n",
    "                                    .select(\"svg\")\n",
    "                                    .selectAll(\"circle\")\n",
    "                                    .data(data, d => d.id)\n",
    "                                    .join(\n",
    "                                        enter => enter.append('circle')\n",
    "                                        .attr(\"cx\", d => map.latLngToLayerPoint([d.lat,d.lng]).x)\n",
    "                                        .attr(\"cy\", d => map.latLngToLayerPoint([d.lat,d.lng]).y)\n",
    "                                        .attr(\"r\", 2)\n",
    "                                        .style(\"fill\", \"green\")\n",
    "                                        .attr(\"stroke\", \"green\")\n",
    "                                        .attr(\"stroke-width\", 1)\n",
    "                                        .attr(\"fill-opacity\", 1) \n",
    "                                        .selection(),\n",
    "\n",
    "                                        update => update\n",
    "                                        .attr(\"cx\", d => map.latLngToLayerPoint([d.lat,d.lng]).x)\n",
    "                                        .attr(\"cy\", d => map.latLngToLayerPoint([d.lat,d.lng]).y)\n",
    "                                        .selection(),\n",
    "\n",
    "                                        exit => exit\n",
    "                                        .remove()\n",
    "                                    )\n",
    "                            });\n",
    "                            current+=1;\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                silent: false, \n",
    "                store_history: false, \n",
    "                stop_on_error: true\n",
    "            }\n",
    "        );\n",
    "    }\n",
    "\n",
    "    function update() {\n",
    "        require(['d3'], function(d3) { \n",
    "            d3.selectAll(\"circle\")\n",
    "            .attr(\"cx\", d => map.latLngToLayerPoint([d.lat,d.lng]).x)\n",
    "            .attr(\"cy\", d => map.latLngToLayerPoint([d.lat,d.lng]).y)\n",
    "        });\n",
    "    } \n",
    "    \n",
    "    function stop(){\n",
    "        IPython.notebook.kernel.execute(\n",
    "            \"stop()\", \n",
    "            {\n",
    "                iopub: {\n",
    "                    output: function(response) {\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                silent: false, \n",
    "                store_history: false, \n",
    "                stop_on_error: true\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    function run(){\n",
    "        current = 0;\n",
    "        IPython.notebook.kernel.execute(\n",
    "            \"start()\", \n",
    "            {\n",
    "                iopub: {\n",
    "                    output: function(response) {\n",
    "                        datInterval = setInterval(fetch, 1000);\n",
    "                        //disable the start button\n",
    "                        document.getElementById(\"start_button\").disabled = true;\n",
    "                        document.getElementById(\"stop_button\").disabled = false;\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                silent: false, \n",
    "                store_history: false, \n",
    "                stop_on_error: true\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    require(['d3','L'], function(d3,L) { \n",
    "        map = L\n",
    "            .map('map')\n",
    "            .setView([40.763231753511604, -73.98383956127027], 10);   // center position + zoom\n",
    "\n",
    "        // Add a tile to the map = a background. Comes from OpenStreetmap\n",
    "        L.tileLayer('https://tile.openstreetmap.org/{z}/{x}/{y}.png', {\n",
    "            maxZoom: 19,\n",
    "            attribution: '© OpenStreetMap'\n",
    "        }).addTo(map);\n",
    "        // Add a svg layer to the map\n",
    "        L.svg().addTo(map);\n",
    "        map.on(\"moveend\", update)\n",
    "    });\n",
    "    \n",
    "    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b4d31",
   "metadata": {},
   "source": [
    "So we can see our Yellow Taxis (they are in green color though!) in action. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26189d11",
   "metadata": {},
   "source": [
    "Finally, let's look at one more aspect of the Volume component in Spatial Big Data:\n",
    "\n",
    "## Limited Main Memory\n",
    "\n",
    "Main memory is where programs and data are kept when the processor is actively using them. When programs and data become active, they are copied from secondary memory into main memory where the processor can interact with them. \n",
    "\n",
    "Main memory is sometimes called **RAM**. RAM stands for **Random Access Memory**.\n",
    "\n",
    "And **RAM is limited.**\n",
    "\n",
    "![RAM](supplementary/images/RAM.jpg)\n",
    "\n",
    "You can always bump up the RAM, but there are design constraints which limits the maximum amount of RAM you can have on a computer.\n",
    "\n",
    "So what if you have a 64GB RAM machine and the spatial data file that you want to process is 500GB (which is not uncommon in the world we live in, for example the entire yellow cab taxi data for NYC from 2009 to 2022 is around 500GB and contained 1.5 billion ride details). You will quickly run into \n",
    "\n",
    "<span STYLE=\"color:red\"> **MemoryError** </span>\n",
    "\n",
    "Since it will be hard for us to replicate a MemoryError for this session (as we are not using any huge datasets), we will show a simulation of MemoryError and a potential solution to get around it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1873d8",
   "metadata": {},
   "source": [
    "In this experiment we will use the taxi zone dataset (which contains the designated taxi zones in NYC) and the taxi ride dataset which contains the details of all taxi rides for a single day in NYC. We need to aggregate the taxi rides to the corresponding taxi zones. The result is the taxi zone dataset with the total count of taxi rides as an additional attribute.\n",
    "\n",
    "![taxi_zone_aggregate](supplementary/images/taxi_zone_aggregate.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08cde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code cell to import the packages for our final exploration.\n",
    "\n",
    "import geopandas as gpd\n",
    "from supplementary import simplereader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37d4bde",
   "metadata": {},
   "source": [
    "## Taxi Zone Data\n",
    "\n",
    "First we will load the taxi zone data for NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ab274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the taxi data\n",
    "taxiZones = simplereader.read_file(r'supplementary/data/taxi_zones/taxi_zones.shp').to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25251b5",
   "metadata": {},
   "source": [
    "There are 263 taxi zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cde4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the zones data by running this code cell.\n",
    "\n",
    "taxiZones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ad581",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot it\n",
    "\n",
    "taxiZones.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753bf83",
   "metadata": {},
   "source": [
    "## Taxi Data\n",
    "Now let's load our taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the taxi data\n",
    "taxidata = simplereader.read_file(r'supplementary/data/taxi1day/taxi1day.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbc02a",
   "metadata": {},
   "source": [
    "Oops!!!!!!! You are suddenly faced with the dreaded **\"MemoryError\"**. But in this case you got a friendly message indicating that you cannot read more than 1000 rows at a time. You get this friendly error message because we have created this error by ourselves. You can see the code details in the file simplereader.py. \n",
    "\n",
    "So how can we proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2da70",
   "metadata": {},
   "source": [
    "## Reading data in chunks\n",
    "\n",
    "A potential solution is to process the data in chunks. Let's look at an illustration.\n",
    "\n",
    "![chunking](supplementary/images/chunking.jpg)\n",
    "\n",
    "As you can see chunking can be used to generate partitions of data. These partitions can further be processed to generate partial results. And at the end, all the partial results can be combined together to generate the final results. This is a very powerful paradigm and can be used to solve very large problems. You can, in theory send these chunks to different threads/cores/or even machines to generate partial results which can all be stitched back to get the final results. Ok, enough of theory, let's see this in action. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba2fe5",
   "metadata": {},
   "source": [
    "From the memory error, the suggestion was to use `read_file_stream` option. Lets look into what `read_file_stream` does\n",
    "\n",
    "```python\n",
    "def read_file_stream(fileName, chunkSize=1000):\n",
    "    fileMeta = fiona.open(fileName)\n",
    "    if chunkSize > MAX_RECORDS:\n",
    "        raise Error(f'chunk size cannot be greater than {MAX_RECORDS} records')\n",
    "    for i in range(0, len(fileMeta), chunkSize):\n",
    "        yield gpd.read_file(fileName, rows = slice(i, i+chunkSize))\n",
    "        \n",
    "```\n",
    "\n",
    "So again a new library to help. \n",
    "```python\n",
    "fileMeta = fiona.open(fileName)\n",
    "```\n",
    "\n",
    "This reads the metadata (data of data) for the shapefile, which has a very small memory footprint than the actual file. Let's try that out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acf35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "fileMeta = fiona.open(r'supplementary/data/taxi1day/taxi1day.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c00577",
   "metadata": {},
   "source": [
    "Now you can get to know how many records are there in the shapefile by just checking the length of this metadata object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fileMeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7cf5b",
   "metadata": {},
   "source": [
    "As you can see there are 470,914 records. Now we will use geopandas to read the shapefile in chunks. Geopandas has a row parameter which can take a `slice()` function. The `slice()` function returns a slice object and is used to specify how to slice a sequence. A quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "aList = [1,2,3,4,5,6,7,8]\n",
    "x = slice(0,3)\n",
    "aList[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea81ccc",
   "metadata": {},
   "source": [
    "For our case, since we know the total number of records (470,914) we can write a for loop that has an interval of CHUNKSIZE (in our case this is set to 1000). Let's simply print the length of the chunks while reading the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(fileMeta),1000):\n",
    "    chunk = gpd.read_file(r'supplementary/data/taxi1day/taxi1day.shp',rows = slice(i,i+1000))\n",
    "    print (len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bf7a2",
   "metadata": {},
   "source": [
    "As you can see each of the chunk is a geodataframe with 1000 records (except the last record which might be different). But rather than just printing the length of the chunk we need to calculate the partial results and then aggregate them to a final dataset. Let's first create that final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3aae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(columns=['OBJECTID', 'counts'])\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ac196",
   "metadata": {},
   "source": [
    "It is a blank dataframe with two columns *OBJECTID* and *counts*\n",
    "\n",
    "Now we will go through the chunks in one by one and each time we will do a point-in-polygon operation using the spatial join operation in geopandas. Then we will combine the current results with the final result and then do an aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This code is complex. The comments outline what each line does\n",
    "\n",
    "# Go through the entire file in chunks of 1000\n",
    "for i in range(0, len(fileMeta), 1000):\n",
    "    \n",
    "    # Read a chunk from the shapefile (shp)\n",
    "    chunk = gpd.read_file(r'supplementary/data/taxi1day/taxi1day.shp', rows = slice(i,i+1000))\n",
    "    \n",
    "    #do the spatial join of taxi zones and the chunk\n",
    "    spatialJoin = taxiZones.sjoin(chunk)\n",
    "    \n",
    "    #now we need to create a dataframe with 'OBJECTID' as a column and counts as the number of times the 'OBJECTID' has occured\n",
    "    current = spatialJoin['OBJECTID'].value_counts().rename_axis('OBJECTID').reset_index(name='counts')\n",
    "    \n",
    "    #now we need to append it to our final dataset. We do that using pd.concat\n",
    "    out = pd.concat((out,current))\n",
    "    \n",
    "    #now we need to perform a groupby sum operation as we need to combine the partial results to a single result\n",
    "    out = out.groupby('OBJECTID',as_index=False)['counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out what the output is:\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d5c87",
   "metadata": {},
   "source": [
    "After the code section has been executed, we get the final aggregated dataframe with two columns, OBJECTID and counts. We can merge back this dataframe to the taxizone dataset so that the taxiZone will have a new column called `counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxiZones = taxiZones.merge(out,on='OBJECTID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out what the new Zones data is:\n",
    "taxiZones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedba691",
   "metadata": {},
   "source": [
    "We can easily see which taxiZones have higher number of rides from them by just sorting the geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e96c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxiZones.sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc94d38",
   "metadata": {},
   "source": [
    "## Success!\n",
    "As we found out, chunking can be an effective strategy to handle memory bottlenecks in RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e9a10",
   "metadata": {},
   "source": [
    "### Explore more...\n",
    "You have done the following: \n",
    "- Learned about what big data is\n",
    "- The 'V's of big data and its relevance to their applications\n",
    "- Explore some big data on the Internet\n",
    "- Load COVID-19 data into a table using Pandas\n",
    "- Parse the data and calculate new columns \n",
    "\n",
    "Here are some pointers for further exploration: \n",
    "- Noticed that there are some calculation returns a value \"NaN\". What does that mean?\n",
    "- Explore more county level COVID-19 data from NY Times at: https://github.com/nytimes/covid-19-data\n",
    "- Load the mask use data: https://github.com/nytimes/covid-19-data/tree/master/mask-use\n",
    "\n",
    "If you are interested, feel free to check out the intermediate lesson. We will introduce more techniques to process, analyze and visualize the big data! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2501f",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "\n",
    "**You have finished an Hour of CI!**\n",
    "\n",
    "\n",
    "But, before you go ... \n",
    "\n",
    "1. Please fill out a very brief questionnaire to provide feedback and help us improve the Hour of CI lessons. It is fast and your feedback is very important to let us know what you learned and how we can improve the lessons in the future.\n",
    "2. If you would like a certificate, then please type your name below and click \"Create Certificate\" and you will be presented with a PDF certificate.\n",
    "\n",
    "<font size=\"+1\"><a style=\"background-color:blue;color:white;padding:12px;margin:10px;font-weight:bold;\" href=\"https://forms.gle/JUUBm76rLB8iYppN7\">Take the questionnaire and provide feedback</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9cc1aa",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# This code cell loads the Interact Textbox that will ask users for their name\n",
    "# Once they click \"Create Certificate\" then it will add their name to the certificate template\n",
    "# And present them a PDF certificate\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "def make_cert(learner_name, lesson_name):\n",
    "    cert_filename = 'hourofci_certificate.pdf'\n",
    "\n",
    "    img = Image.open(\"../../supplementary/hci-certificate-template.jpg\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    cert_font   = ImageFont.truetype('../../supplementary/cruft.ttf', 150)\n",
    "    cert_fontsm = ImageFont.truetype('../../supplementary/cruft.ttf', 80)\n",
    "    \n",
    "    _,_,w,h = cert_font.getbbox(learner_name)  \n",
    "    draw.text( xy = (1650-w/2,1100-h/2), text = learner_name, fill=(0,0,0),font=cert_font)\n",
    "    \n",
    "    _,_,w,h = cert_fontsm.getbbox(lesson_name)\n",
    "    draw.text( xy = (1650-w/2,1100-h/2 + 750), text = lesson_name, fill=(0,0,0),font=cert_fontsm)\n",
    "    \n",
    "    img.save(cert_filename, \"PDF\", resolution=100.0)   \n",
    "    return cert_filename\n",
    "\n",
    "\n",
    "interact_cert=interact.options(manual=True, manual_name=\"Create Certificate\")\n",
    "\n",
    "@interact_cert(name=\"Your Name\")\n",
    "def f(name):\n",
    "    print(\"Congratulations\",name)\n",
    "    filename = make_cert(name, 'Beginner Big Data')\n",
    "    print(\"Download your certificate by clicking the link below.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1789b8",
   "metadata": {},
   "source": [
    "<font size=\"+1\"><a style=\"background-color:blue;color:white;padding:12px;margin:10px;font-weight:bold;\" href=\"hourofci_certificate.pdf?download=1\" download=\"hourofci_certificate.pdf\">Download your certificate</a></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
