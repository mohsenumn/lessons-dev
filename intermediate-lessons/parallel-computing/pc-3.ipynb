{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intermediate Parallel Computing\n",
    "### Segment 2 of 6\n",
    "\n",
    "### Apache Spark, the Spark of a Journey!\n",
    "\n",
    "### In this segment we will answer:\n",
    "* What is Apache Spark?\n",
    "* What is its architecture?\n",
    "* How to install and initiate a Spark computing session?\n",
    "\n",
    "\n",
    "*Lesson Developer: Mohsen Ahmadkhani, ahmad178@umn.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you for helping our study\n",
    "\n",
    "\n",
    "<a href=\"#/slide-1-0\" class=\"navigate-right\" style=\"background-color:blue;color:white;padding:8px;margin:2px;font-weight:bold;\">Continue with the lesson</a>\n",
    "\n",
    "Throughout this lesson you will see reminders, like the one below, to ensure that all participants understand that they are in a voluntary research study.\n",
    "\n",
    "### Reminder\n",
    "\n",
    "<font size=\"+1\">\n",
    "\n",
    "By continuing with this lesson you are granting your permission to take part in this research study for the Hour of Cyberinfrastructure: Developing Cyber Literacy for GIScience project. In this study, you will be learning about cyberinfrastructure and related concepts using a web-based platform that will take approximately one hour per lesson. Participation in this study is voluntary.\n",
    "\n",
    "Participants in this research must be 18 years or older. If you are under the age of 18 then please exit this webpage or navigate to another website such as the Hour of Code at https://hourofcode.com, which is designed for K-12 students.\n",
    "\n",
    "If you are not interested in participating please exit the browser or navigate to this website: http://www.umn.edu. Your participation is voluntary and you are free to stop the lesson at any time.\n",
    "\n",
    "For the full description please navigate to this website: <a href=\"../../gateway-lesson/gateway/gateway-1.ipynb\">Gateway Lesson Research Study Permission</a>.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "Hide"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " \n",
       "    <script type=\"text/javascript\" src=\"../../supplementary/js/custom.js\"></script>\n",
       "    \n",
       "    <style>\n",
       "        .output_prompt{opacity:0;}\n",
       "    </style>\n",
       "    \n",
       "    <input id=\"toggle_code\" type=\"button\" value=\"Toggle raw code\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code cell starts the necessary setup for Hour of CI lesson notebooks.\n",
    "# First, it enables users to hide and unhide code by producing a 'Toggle raw code' button below.\n",
    "# Second, it imports the hourofci package, which is necessary for lessons and interactive Jupyter Widgets.\n",
    "# Third, it helps hide/control other aspects of Jupyter Notebooks to improve the user experience\n",
    "# This is an initialization cell\n",
    "# It is not displayed because the Slide Type is 'Skip'\n",
    "\n",
    "from IPython.display import HTML, IFrame, Javascript, display\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n",
    "import getpass # This library allows us to get the username (User agent string)\n",
    "\n",
    "# import package for hourofci project\n",
    "import sys\n",
    "sys.path.append('../../supplementary') # relative path (may change depending on the location of the lesson notebook)\n",
    "import hourofci\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Hide warnings\n",
    "\n",
    "# load javascript to initialize/hide cells, get user agent string, and hide output indicator\n",
    "# hide code by introducing a toggle button \"Toggle raw code\"\n",
    "# HTML(''' \n",
    "#     <script type=\"text/javascript\" src=\\\"../../supplementary/js/custom.js\\\"></script>\n",
    "    \n",
    "#     <input id=\"toggle_code\" type=\"button\" value=\"Toggle raw code\">\n",
    "# ''')\n",
    "\n",
    "HTML(''' \n",
    "    <script type=\"text/javascript\" src=\\\"../../supplementary/js/custom.js\\\"></script>\n",
    "    \n",
    "    <style>\n",
    "        .output_prompt{opacity:0;}\n",
    "    </style>\n",
    "    \n",
    "    <input id=\"toggle_code\" type=\"button\" value=\"Toggle raw code\">\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Apache Spark?\n",
    "\n",
    "Apache Spark is an open-source data processing framework designed to carry out processing tasks on large volumes of data. It enables dividing of data into smaller chunks and distributing them between multiple processing units to perform multiple data processing tasks at the same time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Apache Spark architecture\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr style=\"background: #fff; text-align: left; vertical-align:\">\n",
    "        <td style=\"background: #fff; text-align: left; font-size: 23px;\">\n",
    "            <ul>\n",
    "                <li>\n",
    "                    <b>Driver Program:</b> The code we write to process our data using the Apache Spark framework is indeed the driver program. In the driver program, the first thing we do is build a Spark Session.\n",
    "                </li>\n",
    "                <li>\n",
    "                    <b>Spark Session:</b> Spark Session is a gateway to all Spark functionalities (methods, data types, etc.). \n",
    "                </li>\n",
    "                <li>\n",
    "                    <b>Cluster Manager:</b> The cluster manager takes care of dividing the job into multiple smaller tasks and distributes them between worker nodes. \n",
    "                </li>\n",
    "                <li>\n",
    "                    <b>Worker Node:</b> A worker node executes the tasks assigned by the cluster manager. Each worker node has one or more executors that can have multiple tasks to execute in parallel.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </td>\n",
    "        <td style=\"width: 50%; background: #fff; text-align: left; vertical-align: top;\"> \n",
    "            <img src=\"supplementary/spark_ar.png\" width=\"100%\">\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before jumping into the code...\n",
    "<table>\n",
    "    <tr style=\"background: #fff; text-align: left; vertical-align:\">\n",
    "        <td style=\"background: #fff; text-align: left; font-size: 23px;\">\n",
    "            <p>Apache Spark has a core engine and four extensions:</p>\n",
    "            <ul>\n",
    "                <li>\n",
    "<b>Spark SQL (enables executing SQL queries on data)</b>\n",
    "                </li>\n",
    "                <li>\n",
    "Spark Streaming (streaming data add-on)\n",
    "                </li>\n",
    "                <li>\n",
    "Spark MLlib (set of machine learning libraries)\n",
    "                </li>\n",
    "                <li>\n",
    "GraphX (designed for distributed graph processing)\n",
    "                </li>\n",
    "            </ul>\n",
    "</td>\n",
    "     <td style=\"width: 40%; background: #fff; text-align: left; vertical-align: top;\"> <img src='https://blog.kakaocdn.net/dn/uO5KB/btqA2a0rio3/n95MXm1PSKxJzz1oaoCA21/img.png?raw=1' width=\"500\" height=\"700\" alt='map'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "In this lesson, we will focus on **Spark SQL** only. Let's start by installing PySpark and then writing the driver program. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we need to install the Python version of Spark. It's called PySpark. <br>\n",
    "Run the cell below to install it using python package installer. <br>\n",
    "<br>\n",
    "Don't worry about restarting the kernel. We will do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, click the \"Restart Kernel\" to update the list of installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <script id=\"p1\">\n",
       "                function restart_kernel(){\n",
       "                    IPython.notebook.kernel.restart();\n",
       "                    var element = document.getElementById('p1').parentElement;\n",
       "                    element.innerHTML = \"Kernel restarted successfully!\"+\"<br/>\"+\"Move on to the next slide.\";\n",
       "               }\n",
       "            </script>\n",
       "            <button onclick=\"restart_kernel()\">Restart Kernel</button>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def restarter():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script id=\"p1\">\n",
    "                function restart_kernel(){\n",
    "                    IPython.notebook.kernel.restart();\n",
    "                    var element = document.getElementById('p1').parentElement;\n",
    "                    element.innerHTML = \"Kernel restarted successfully!\"+\"<br/>\"+\"Move on to the next slide.\";\n",
    "               }\n",
    "            </script>\n",
    "            <button onclick=\"restart_kernel()\">Restart Kernel</button>\n",
    "        '''\n",
    "    ))\n",
    "    \n",
    "restarter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Allright, now let's build a Spark Session. Remember, this is the first thing to do in the driver program. \n",
    "\n",
    "We use `SparkConf()` function to set a name to our application and specify the number of threads for our program to run. \n",
    "\n",
    "Here, we call it `hourofci` and specify 4 **threads** in our local machine then store the session in a variable named `spark`. Run the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf().setAppName(\"hourofci\").setMaster(\"local[4]\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cool! Now we have a platform to perform our data analysis using 4 threads in parallel! \n",
    "\n",
    "Now, quiz time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c6658c2335464d8478aa7fd503ce86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Is the number of threads equivalent to the number of physical CPU cores in our machi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e70d301c6de4a5c92cc598102bf9165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', icon='check', layout=Layout(height='auto', width='auto'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb613ad000024d9e8fbdebb51dd8f5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget1 = widgets.RadioButtons(\n",
    "    options = ['No', 'Yes'],\n",
    "    description = 'Is the number of threads equivalent to the number of physical CPU cores in our machine?', style={'description_width': 'initial'},\n",
    "    layout = Layout(width='100%',display=\"flex\", justify_content=\"flex-start\"),\n",
    "    value = None\n",
    ")\n",
    "\n",
    "display(widget1)\n",
    "\n",
    "hourofci.SubmitBtn2(widget1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Threads Vs. physical CPU Cores\n",
    "\n",
    "Unlike what it sounds, threads and CPU cores are **NOT** the same. \n",
    "To explain threads let's get back to our grocery store analogy. \n",
    "\n",
    "Normally, a grocery store has a **checkout section** with one or more **cashiers** working in this section. You (a customer) unload your purchased items on a cashier's **conveyor belt** and the cashier's job is to pick up and scan your items. \n",
    "\n",
    "In the computer/grocery analogy:\n",
    "<ul>\n",
    "    <li>\n",
    "        the <font style=\"font-weight: bold; color:red\">checkout section</font> would be the <font style=\"font-weight: bold; color:red\">CPU</font>,\n",
    "    </li> \n",
    "    <li>\n",
    "        each <font style=\"font-weight: bold; color:blue\">cashier</font> is equivalent to a <font style=\"font-weight: bold; color:blue\">physical core</font>,\n",
    "    </li>\n",
    "    <li>\n",
    "        and the <font style=\"font-weight: bold; color:green\">conveyor belt</font> would be analogous to a single <font style=\"font-weight: bold; color:green\">thread</font>. \n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "So, in a fantasy world, if a cashier can handle two customers (= two conveyor belts) at the same time, it would be the case of a single core with two threads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelizing Using Threads!\n",
    "\n",
    "The number of threads is the number of gates you specify to process your data in parallel. We saw how to use `setMaster()` function to pass the variable `local` to specify the number of threads. The followings are the available parallelism options:\n",
    "\n",
    "* `local`: Run Spark with a single thread - No parallelism at all!\n",
    "\n",
    "* `local[N]`: Run Spark with N multiple threads.\n",
    "\n",
    "* `local[*]`: Set the number of threads as same as the number of available physical CPU cores on your machine.\n",
    "\n",
    "\n",
    "Click back 3 slides to re-visit the code where we set the number of threads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "If you are curious to see how many physical cores are available on the HourofCI server (<a href=\"https://jetstream-cloud.org\">Jetstream2</a>) right now, run the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print('The number of available physical CPU cores: ', os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Great! You now have a general sense of what Spark is and how to install and load it!<br> \n",
    "In the next segment we will get into some more details of **Spark SQL**.<br><br>\n",
    "\n",
    "\n",
    "<font size=\"+1\"><a style=\"background-color:blue;color:white;padding:12px;margin:10px;font-weight:bold;\" href=\"pc-4.ipynb\">Click here to go to the next notebook.</a></font>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "rise": {
   "autolaunch": true,
   "overlay": "<div class='hciheader'></div><div class='hcifooter'></div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
