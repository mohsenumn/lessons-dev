{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Parallel Computing\n",
    "\n",
    "### Segment 5 of 5\n",
    "\n",
    "### PySpark SQL III: Spatial is Special!\n",
    "\n",
    "#### In this segment we will learn:\n",
    "* Apache Sedona\n",
    "* Querying spatial data with PySpark SQL.\n",
    "\n",
    "\n",
    "*Lesson Developer: Mohsen Ahmadkhani, ahmad178@umn.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder\n",
    "<a href=\"#/slide-2-0\" class=\"navigate-right\" style=\"background-color:blue;color:white;padding:8px;margin:2px;font-weight:bold;\">Continue with the lesson</a>\n",
    "\n",
    "<br>\n",
    "</br>\n",
    "<font size=\"+1\">\n",
    "\n",
    "By continuing with this lesson you are granting your permission to take part in this research study for the Hour of Cyberinfrastructure: Developing Cyber Literacy for GIScience project. In this study, you will be learning about cyberinfrastructure and related concepts using a web-based platform that will take approximately one hour per lesson. Participation in this study is voluntary.\n",
    "\n",
    "Participants in this research must be 18 years or older. If you are under the age of 18 then please exit this webpage or navigate to another website such as the Hour of Code at https://hourofcode.com, which is designed for K-12 students.\n",
    "\n",
    "If you are not interested in participating please exit the browser or navigate to this website: http://www.umn.edu. Your participation is voluntary and you are free to stop the lesson at any time.\n",
    "\n",
    "For the full description please navigate to this website: <a href=\"../../gateway-lesson/gateway/gateway-1.ipynb\">Gateway Lesson Research Study Permission</a>.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "init_cell": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "Hide"
    ]
   },
   "outputs": [],
   "source": [
    "# This code cell starts the necessary setup for Hour of CI lesson notebooks.\n",
    "# First, it enables users to hide and unhide code by producing a 'Toggle raw code' button below.\n",
    "# Second, it imports the hourofci package, which is necessary for lessons and interactive Jupyter Widgets.\n",
    "# Third, it helps hide/control other aspects of Jupyter Notebooks to improve the user experience\n",
    "# This is an initialization cell\n",
    "# It is not displayed because the Slide Type is 'Skip'\n",
    "\n",
    "from IPython.display import HTML, IFrame, Javascript, display\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n",
    "import getpass # This library allows us to get the username (User agent string)\n",
    "\n",
    "# import package for hourofci project\n",
    "import sys\n",
    "sys.path.append('../../supplementary') # relative path (may change depending on the location of the lesson notebook)\n",
    "import hourofci\n",
    "\n",
    "# load javascript to initialize/hide cells, get user agent string, and hide output indicator\n",
    "# hide code by introducing a toggle button \"Toggle raw code\"\n",
    "HTML(''' \n",
    "    <script type=\"text/javascript\" src=\\\"../../supplementary/js/custom.js\\\"></script>\n",
    "    \n",
    "    <style>\n",
    "        .output_prompt{opacity:0;}\n",
    "    </style>\n",
    "    \n",
    "    <input id=\"toggle_code\" type=\"button\" value=\"Toggle raw code\">\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Distributed Spatial Computing?\n",
    "\n",
    "<center><img src=https://media.makeameme.org/created/why-even-bother-5c8eb2.jpg width=300></center>\n",
    "In recent years, the spatial technology has evolved tremendously resulted in BIG spatial data. Some examples of spatial big data include location-based services like Uber, Lyft, scooter ride companies and many more, remote sensing data, spatial social networks' data like twitter and FaceBook, weather maps, transportation, and countless others. Handling such BIG load of spatial data needs <b>faster</b> database management technologies, and parallel computing is faster!\n",
    "\n",
    "By the way, if you are curious about spatial big data, we talked about it in the <a href=\"http://try.hourofci.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fhourofci%2Flessons&urlpath=tree%2Flessons%2Fintermediate-lessons%2Fbig-data%2FWelcome.ipynb&branch=master\">intermediate Big Data</a> lesson. So, take a look if you have not already.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Sedona\n",
    "\n",
    "SO far, we briefly saw how Apache Spark works but like most data management technologies, Apache Spark also first was developed for non-spatial data. Why? well, because <b>spatial is special!</b> Due to nature of spatial data type, it is much more complex and therefore harder to store and analyse. \n",
    "To support spatial data type, people at Apache launched an extension to Spark named <b><a href=\"http://sedona.apache.org\">Apache Sedona</a></b>. \n",
    "\n",
    "Apache Sedona (formerly GeoSpark) is a powerful tool that extends RDDs to geospatial RDDs (aka SpatialRDD). In simple words Apache Sedona enables two major things: \n",
    "<ol>\n",
    "    <li>\n",
    "Distributing geospatial data between multiple computational cores \n",
    "    </li>\n",
    "    <li>\n",
    "Spatial functions and queries in SparkSQL\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "In this segment we touch on Apache Sedona and see how it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import `SparkSession` from SparkSQL as the initial step in Spark framework. Then we need to import a few sub-modules from Sedona. But we need to install the `Apache Sedona` package first. Let's do it in the next cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install apache-sedona --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, click the \"Restart Kernel\" to update the list of installed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [],
   "source": [
    "def restarter():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                function restart_kernel(){\n",
    "                    IPython.notebook.kernel.restart();\n",
    "                }\n",
    "            </script>\n",
    "            <button onclick=\"restart_kernel()\">Restart Kernel</button>\n",
    "        '''\n",
    "    ))\n",
    "restarter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import a couple of general packages for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from ipyleaflet import Map, GeoData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a spatially enabled spark context using the imported Sedona sub-modules. Don't worry too much if it looks compicated! You can copy and paste this for your project :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"Spatial Spark Demo\").\\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName).\\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) .\\\n",
    "    config(\"spark.jars.packages\", \"org.apache.sedona:sedona-python-adapter-3.0_2.12:1.2.1-incubating,org.datasyslab:geotools-wrapper:1.1.0-25.2\") .\\\n",
    "    getOrCreate()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading demo shapefiles to illustrate Apache Sedona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this segment, we will use two shapefiles to demonstrate the functionalities of Apache Sedona. These shapefiles include a rivers' and the US state boundaries dataset.\n",
    "\n",
    "Ok, let's download the dataset of rivers and lake centerlines for the entire world using `wget`. This is the same dataset we used <a href=\"http://try.hourofci.org/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fhourofci%2Flessons&urlpath=tree%2Flessons%2Fbeginner-lessons%2Fgeospatial-data%2Fgd-example_1.ipynb&branch=master\">here</a> in the beginner geospatial data lesson. You can learn more about this dataset there. \n",
    "\n",
    "Run the cell below to download the dataset as a zip file and then extract the shapefile using `unzip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O ne_10m_rivers_lake_centerlines.zip https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/10m/physical/ne_10m_rivers_lake_centerlines.zip \n",
    "!unzip -n ne_10m_rivers_lake_centerlines.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the shapefile using geopandas and take a look at the first few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = gpd.read_file('ne_10m_rivers_lake_centerlines.shp')\n",
    "rivers = rivers[['featurecla', 'name', 'name_alt', 'rivernum', 'geometry']]\n",
    "rivers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, there is a `geometry` column there too! That's what makes it a spatial dataset. Now let's plot it and see the line features of rivers and lake centerlines on the map. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_layer = GeoData(geo_dataframe = rivers, style={'color':'blue'})\n",
    "mymap1 = Map(center=(40,10), zoom = 2)\n",
    "mymap1.add_layer(rivers_layer)\n",
    "mymap1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! \n",
    "\n",
    "Now we will do the same for the `US states` shapefile. This is a shapefile of the US states' boundaries downloaded from the <a href=\"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjBpayMwJn7AhV2lGoFHbfWB_cQFnoECAsQAQ&url=https%3A%2F%2Fwww.census.gov%2Fgeographies%2Fmapping-files%2Ftime-series%2Fgeo%2Fcarto-boundary-file.html&usg=AOvVaw2QKo7f-rChpkoO7zQ9E75A\">US Census government</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O us_states.zip https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_20m.zip \n",
    "!unzip -n us_states.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = gpd.read_file('us_states.zip')\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "states_layer = GeoData(geo_dataframe = states, style={'color':'red'})\n",
    "mymap2 = Map(center=(40,-100), zoom = 4)\n",
    "mymap2.add_layer(states_layer)\n",
    "mymap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting GeoPandas to Apache Sedona\n",
    "\n",
    "So far, the shapefiles have been loaded as geopandas dataframes. In order to enable parallel computation, we need to convert them to spark dataframes. This is easy! Just use Spark's `createDataFrame` method as below. \n",
    "\n",
    "Here we also print the dataframe's schema to see what columns and data types we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_spdf = spark.createDataFrame(states)\n",
    "states_spdf.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at the very buttom of the schema there is a `geometry` data type! That's what Sedona braught to us. \n",
    "\n",
    "Next we use `show` method to see a few first rows of the spark dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states_spdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And same process for the rivers' dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_spdf = spark.createDataFrame(rivers)\n",
    "rivers_spdf.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_spdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SQL Views (Virtual Tables)\n",
    "\n",
    "Similar to non-spatial data, we need to create SQL Views for each of the dataframes we have. This is a required step to enable querying data in SQL and literally means creating virtual relations (tables) for dataframes. Below, we do this using `createOrReplaceTempView` method and create two Views named `rivers` and `states`. We will query from these two tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_spdf.createOrReplaceTempView(\"rivers\")\n",
    "states_spdf.createOrReplaceTempView(\"states\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Demo Spatial Query \n",
    "As an example, suppose we want to see which rivers and lake centerlines cross the boundaries of Minnesota and Washington states. This is indeed a spatial query as we care about the geographical (topological) relations of features. \n",
    "\n",
    "One way to write this query is as follows:<br>\n",
    "In this SQL query, we select state and river names along with the rivers' geometry. \n",
    "\n",
    "Under the `WHERE` clause, we say if the state name is either Minnesota OR Washington AND the rivers that intersect the polygons of these two states. \n",
    "\n",
    "```sql\n",
    "SELECT s.NAME, r.name river_name, r.geometry geom\n",
    "FROM states s, rivers r\n",
    "WHERE s.NAME IN ('Minnesota', 'Washington') and ST_INTERSECTS(r.geometry, s.geometry)\n",
    "```\n",
    "\n",
    "Let's execute this spatial query together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_rivers = spark.sql(\"\"\"\n",
    "SELECT s.NAME, r.name river_name, r.geometry geom\n",
    "FROM states s, rivers r\n",
    "WHERE s.NAME IN ('Minnesota', 'Washington') and ST_INTERSECTS(r.geometry, s.geometry)\n",
    "\"\"\")\n",
    "\n",
    "mn_rivers.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Friends, spatial queries like this one would take much longer if you do not partition them. Please note that this difference is more significant for larger datasets as the \"distribution\" of data between multiple cores itself could be time consuming. Hence, for small datasets we do not usually use parallel computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Apache Sedona to GeoPandas\n",
    "\n",
    "Ok, we queried our data and returned all rivers that have the conditions we set. Now to spatially visualize them we need to convert the result back to geopandas dataframe. To do this we simply use `toPandas` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_rivers_df = mn_rivers.toPandas()\n",
    "result = gpd.GeoDataFrame(mn_rivers_df, geometry=\"geom\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the result on a map! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_mn = states[(states['NAME']=='Minnesota') | (states['NAME']=='Washington')]\n",
    "wa_mn_layer = GeoData(geo_dataframe = wa_mn, style={'color':'red'})\n",
    "gdf_layer = GeoData(geo_dataframe = result, style={'color':'blue'})\n",
    "gdf_map = Map(center=(40,-100), zoom = 4)\n",
    "gdf_map.add_layer(gdf_layer)\n",
    "gdf_map.add_layer(wa_mn_layer)\n",
    "gdf_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Last Example\n",
    "\n",
    ">**QUESTION:** What cafes in St Paul, MN are in 50-meter neighborhood of Mississippi river?\n",
    "\n",
    "To answer this question we need two datasets and their corresponding SQL relations (i.e., Views) including the rivers' dataset and the coffee shop dataset. \n",
    "\n",
    "We already have created the rivers' SQL View, below we start downloading the point dataset of cafes in St Paul from OpenStreetMap liberary and convert it to Apache Sedona SQL View. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox \n",
    "\n",
    "place = 'St Paul, MN'\n",
    "tags = {'amenity':'cafe', 'cuisine':'coffee-shop'}  \n",
    "coffee_shops = ox.geometries_from_place(place, tags) \n",
    "coffee_shops = coffee_shops.to_crs('epsg:4326')[['name', 'geometry']]\n",
    "coffee_shops = coffee_shops[coffee_shops['geometry'].type == 'Point']\n",
    "coffee_shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_shops_layer = GeoData(geo_dataframe = coffee_shops, point_style={'color': 'black'})\n",
    "mymap3 = Map(center=(44.96,-93.13), zoom = 11)\n",
    "mymap3.add_layer(coffee_shops_layer)\n",
    "mymap3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's create the SQL View of the cafes' dataset as follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_shops_spdf = spark.createDataFrame(coffee_shops)\n",
    "coffee_shops_spdf.createOrReplaceTempView(\"cafes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "One way to answer the question is the following spatial query. We first want to build a budder of 50 meters around each cafe and then see which of them intersect with the Mississippi river. \n",
    "\n",
    ">```sql\n",
    "SELECT c.name cafe, c.geometry as geom\n",
    "FROM cafes c, rivers r\n",
    "WHERE r.name = 'Mississippi' and ST_INTERSECTS(ST_TRANSFORM(r.geometry, 'epsg:4326','epsg:2180'), ST_BUFFER(ST_TRANSFORM(c.geometry, 'epsg:4326','epsg:2180'), 50))\n",
    "\n",
    "\n",
    "In this query we used `ST_TRANSFORM` function to reproject our data to a projection system that uses meters as length unit.  Then we applied `ST_BUFFER` function to build a buffer of 50 meters around each cafe. Finally, we used `ST_INTERSECTS` to see if the Mississipi river intersects with the buffers. Let's execute this query in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riverside_cafes = spark.sql(\"\"\"\n",
    "SELECT c.name cafe, c.geometry as geom\n",
    "FROM cafes c, rivers r\n",
    "WHERE r.name = 'Mississippi' and ST_INTERSECTS(ST_TRANSFORM(r.geometry, 'epsg:4326','epsg:2180'), ST_BUFFER(ST_TRANSFORM(c.geometry, 'epsg:4326','epsg:2180'), 50))\n",
    "\"\"\")\n",
    "\n",
    "riverside_cafes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sounds good! Now, you know which cafe to go when you crave for a triple-shot Espresso with an outlook of Mississippi river in St Paul!!\n",
    "\n",
    "Do you want to see them on the map?! Run the cell below. \n",
    "\n",
    "The queried cafes are colored in red and the others remained black. Also, the Mississippi river is displayed in blue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "riverside_cafesdf = riverside_cafes.toPandas()\n",
    "riverside_cafesdf = gpd.GeoDataFrame(riverside_cafesdf, geometry=\"geom\")\n",
    "riverside_cafes_layer = GeoData(geo_dataframe = riverside_cafesdf, point_style={'color': 'red'})\n",
    "\n",
    "coffee_shops_layer = GeoData(geo_dataframe = coffee_shops, point_style={'color': 'black'})\n",
    "\n",
    "mymap4 = Map(center=(44.96,-93.13), zoom = 11)\n",
    "mymap4.add_layer(coffee_shops_layer)\n",
    "mymap4.add_layer(gdf_layer)\n",
    "mymap4.add_layer(riverside_cafes_layer)\n",
    "mymap4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Else?\n",
    "\n",
    "Apache Sedona enables tens of other spatial functions like centroid, distance, transformation, buffer and many more that we cannot cover them all here. \n",
    "\n",
    "You can see a list of all available spatial functions at https://sedona.apache.org/api/sql/Function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "\n",
    "**You have finished an Hour of CI!**\n",
    "\n",
    "\n",
    "But, before you go ... \n",
    "\n",
    "1. Please fill out a very brief questionnaire to provide feedback and help us improve the Hour of CI lessons. It is fast and your feedback is very important to let us know what you learned and how we can improve the lessons in the future.\n",
    "2. If you would like a certificate, then please type your name below and click \"Create Certificate\" and you will be presented with a PDF certificate.\n",
    "\n",
    "<font size=\"+1\"><a style=\"background-color:blue;color:white;padding:12px;margin:10px;font-weight:bold;\" href=\"https://forms.gle/JUUBm76rLB8iYppN7\">Take the questionnaire and provide feedback</a></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "Hide",
     "Init"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# This code cell loads the Interact Textbox that will ask users for their name\n",
    "# Once they click \"Create Certificate\" then it will add their name to the certificate template\n",
    "# And present them a PDF certificate\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "def make_cert(learner_name, lesson_name):\n",
    "    cert_filename = 'hourofci_certificate.pdf'\n",
    "\n",
    "    img = Image.open(\"../../supplementary/hci-certificate-template.jpg\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    cert_font   = ImageFont.truetype('../../supplementary/cruft.ttf', 150)\n",
    "    cert_fontsm = ImageFont.truetype('../../supplementary/cruft.ttf', 80)\n",
    "    \n",
    "    _,_,w,h = cert_font.getbbox(learner_name)  \n",
    "    draw.text( xy = (1650-w/2,1100-h/2), text = learner_name, fill=(0,0,0),font=cert_font)\n",
    "    \n",
    "    _,_,w,h = cert_fontsm.getbbox(lesson_name)\n",
    "    draw.text( xy = (1650-w/2,1100-h/2 + 750), text = lesson_name, fill=(0,0,0),font=cert_fontsm)\n",
    "    \n",
    "    img.save(cert_filename, \"PDF\", resolution=100.0)   \n",
    "    return cert_filename\n",
    "\n",
    "\n",
    "interact_cert=interact.options(manual=True, manual_name=\"Create Certificate\")\n",
    "\n",
    "@interact_cert(name=\"Your Name\")\n",
    "def f(name):\n",
    "    print(\"Congratulations\",name)\n",
    "    filename = make_cert(name, 'Intermediate Parallel Computing')\n",
    "    print(\"Download your certificate by clicking the link below.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\"><a style=\"background-color:blue;color:white;padding:12px;margin:10px;font-weight:bold;\" href=\"hourofci_certificate.pdf?download=1\" download=\"hourofci_certificate.pdf\">Download your certificate</a></font>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
